name: Update GitHub Stats

on:
  schedule:
    - cron: "*/15 * * * *"
  workflow_dispatch:
  push:
    branches:
      - main

jobs:
  update-stats:
    runs-on: ubuntu-latest
    if: github.repository_owner == 'nicholasjano'
    steps:
      - name: Check GitHub API Rate Limits
        id: rate_limit
        run: |
          # Maximum retries in case of API failure
          MAX_RETRIES=3
          RETRY_DELAY=5  # Wait 5 seconds between retries

          # Function to fetch the GitHub API rate limit
          fetch_rate_limit() {
            curl -s -H "Authorization: bearer ${{ secrets.PAT_TOKEN }}" \
                    -H "Content-Type: application/json" \
                    "https://api.github.com/rate_limit"
          }

          for ((i=1; i<=MAX_RETRIES; i++)); do
            # Fetch rate limit with retry logic
            RESPONSE=$(fetch_rate_limit)

            # Ensure response is not empty
            if [[ -z "$RESPONSE" ]]; then
              echo "Error: Empty response from GitHub API (Attempt $i/$MAX_RETRIES)"
            else
              # Extract rate limit remaining and reset time using jq
              RATE_LIMIT=$(echo "$RESPONSE" | jq -r '.rate.remaining' 2>/dev/null)
              RATE_RESET=$(echo "$RESPONSE" | jq -r '.rate.reset' 2>/dev/null)

              # Ensure we got valid numeric values
              if [[ -n "$RATE_LIMIT" && "$RATE_LIMIT" =~ ^[0-9]+$ ]]; then
                if (( RATE_LIMIT < 100 )); then
                  RESET_TIME=$(date -d "@$RATE_RESET" '+%Y-%m-%d %H:%M:%S UTC' 2>/dev/null || echo "unknown")
                  echo "GitHub API rate limit too low: $RATE_LIMIT. Reset at: $RESET_TIME"
                  exit 1
                fi
                echo "GitHub API rate limit is sufficient: $RATE_LIMIT"
                exit 0
              else
                echo "Error: Could not parse rate limit. Response: $RESPONSE (Attempt $i/$MAX_RETRIES)"
              fi
            fi

            # Wait before retrying
            if (( i < MAX_RETRIES )); then
              echo "Retrying in $RETRY_DELAY seconds..."
              sleep $RETRY_DELAY
            fi
          done

          echo "Failed to fetch GitHub API rate limit after $MAX_RETRIES attempts."
          exit 1

      - name: Calculate date one month ago (EST)
        id: datecalc
        run: |
          export TZ="America/New_York"

          # Get today's date in EST
          TODAY=$(TZ="America/New_York" date +"%Y-%m-%d")

          # Extract components
          YEAR=$(date -d "$TODAY" +"%Y")
          MONTH=$(date -d "$TODAY" +"%m")
          DAY=$(date -d "$TODAY" +"%d")

          # Compute the previous month
          if [ "$MONTH" -eq 01 ]; then
            PREV_MONTH=12
            PREV_YEAR=$((YEAR - 1))
          else
            PREV_MONTH=$((10#$MONTH - 1))
            PREV_YEAR=$YEAR
          fi

          # Format previous month as two digits
          PREV_MONTH=$(printf "%02d" $PREV_MONTH)

          # Find last day of the previous month
          LAST_DAY_OF_PREV_MONTH=$(date -d "$PREV_YEAR-$PREV_MONTH-01 +1 month -1 day" +"%d")

          # Determine the correct day to use
          if [ "$DAY" -gt "$LAST_DAY_OF_PREV_MONTH" ]; then
            FINAL_DAY=$LAST_DAY_OF_PREV_MONTH
          else
            FINAL_DAY=$DAY
          fi

          # Construct the final date in ISO 8601 format
          ONE_MONTH_AGO=$(date -d "$PREV_YEAR-$PREV_MONTH-$FINAL_DAY 00:00:00 UTC" +"%Y-%m-%dT00:00:00Z")

          echo "Computed one_month_ago: $ONE_MONTH_AGO"
          echo "one_month_ago=$ONE_MONTH_AGO" >> $GITHUB_OUTPUT

      - name: Fetch GitHub Stats (Total Commits, Unique Repos)
        id: fetch_stats
        run: |
          DATE_QUERY=${{ steps.datecalc.outputs.one_month_ago }}
          CURRENT_DATE=$(date -u +"%Y-%m-%dT00:00:00Z")

          # Fetch the non-paginated data (total commits and unique repos for the month)
          INITIAL_QUERY='{"query":"query{user(login:\"nicholasjano\"){contributionsCollection(from:\"'"$DATE_QUERY"'\",to:\"'"$CURRENT_DATE"'\"){totalCommitContributions commitContributionsByRepository{repository{id}}}}}"}'

          # Execute the initial query
          INITIAL_RESPONSE=$(curl -s -X POST -H "Authorization: bearer ${{ secrets.PAT_TOKEN }}" \
            -H "Content-Type: application/json" \
            https://api.github.com/graphql \
            -d "$INITIAL_QUERY")

          # Check for errors in initial response
          if echo "$INITIAL_RESPONSE" | jq -e 'has("errors")' > /dev/null; then
            ERROR_MESSAGE=$(echo "$INITIAL_RESPONSE" | jq -r '.errors[0].message')
            echo "Error in initial query: $ERROR_MESSAGE"
            exit 1
          fi

          # Check if the data path exists
          if ! echo "$INITIAL_RESPONSE" | jq -e '.data' > /dev/null; then
            echo "Error: No data field in response"
            exit 1
          fi

          # Extract total commits and unique repos with null checks
          TOTAL_COMMITS=$(echo "$INITIAL_RESPONSE" | jq '.data.user.contributionsCollection.totalCommitContributions // 0')
          UNIQUE_REPOS=$(echo "$INITIAL_RESPONSE" | jq '.data.user.contributionsCollection.commitContributionsByRepository | length // 0')

          # Store values in GitHub Actions outputs
          {
            echo "total_commits=$TOTAL_COMMITS"
            echo "unique_repos=$UNIQUE_REPOS"
          } >> $GITHUB_OUTPUT

      - name: Create stats JSON file
        run: |
          echo "{" > stats.json
          echo "  \"totalCommitsPastMonth\": ${{ steps.fetch_stats.outputs.total_commits }}," >> stats.json
          echo "  \"uniqueRepositoriesPastMonth\": ${{ steps.fetch_stats.outputs.unique_repos }}" >> stats.json
          echo "}" >> stats.json

      - name: Install AWS CLI
        run: |
          pip install awscli || exit 1

      - name: Upload stats.json to R2
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.R2_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.R2_SECRET_ACCESS_KEY }}
          R2_ENDPOINT: ${{ secrets.R2_ENDPOINT }}
          R2_BUCKET: ${{ secrets.R2_BUCKET }}
        run: |
          # Check if file exists
          if [ ! -f stats.json ]; then
            echo "Error: stats.json file not found"
            exit 1
          fi

          # Check if file is valid JSON
          if ! jq empty stats.json 2>/dev/null; then
            echo "Error: stats.json is not valid JSON"
            exit 1
          fi

          # Attempt upload with retries
          for i in {1..3}; do
            if aws s3 cp stats.json s3://${R2_BUCKET}/stats.json \
              --endpoint-url ${R2_ENDPOINT} \
              --cache-control "no-store, no-cache" \
              --content-type "application/json"; then
              echo "Successfully uploaded stats.json to R2"
              exit 0
            else
              echo "Attempt $i failed, retrying in 5 seconds..."
              sleep 5
            fi
          done

          echo "Error: Failed to upload stats.json after 3 attempts"
          exit 1
